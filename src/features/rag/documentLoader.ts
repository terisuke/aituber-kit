import { TextLoader } from 'langchain/document_loaders/fs/text'
import { RecursiveCharacterTextSplitter } from 'langchain/text_splitter'
import { Document } from 'langchain/document'
import { createOllamaEmbeddings } from './embeddings'
import { createChromaCollection, DEFAULT_CHROMA_CONFIG } from './chromaClient'
import * as fs from 'fs'
import * as path from 'path'

/**
 * ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿ã€ãƒãƒ£ãƒ³ã‚¯ã«åˆ†å‰²ã™ã‚‹
 * @param filePath ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
 * @param chunkSize ãƒãƒ£ãƒ³ã‚¯ã‚µã‚¤ã‚ºï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 1000ï¼‰
 * @param chunkOverlap ãƒãƒ£ãƒ³ã‚¯ã‚ªãƒ¼ãƒãƒ¼ãƒ©ãƒƒãƒ—ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 200ï¼‰
 * @returns åˆ†å‰²ã•ã‚ŒãŸãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆé…åˆ—
 */
export async function loadAndSplitDocument(
  filePath: string,
  chunkSize: number = 1000,
  chunkOverlap: number = 200
): Promise<Document[]> {
  const loader = new TextLoader(filePath)
  const docs = await loader.load()

  const splitter = new RecursiveCharacterTextSplitter({
    chunkSize,
    chunkOverlap,
    separators: ['\n\n', '\n', ' ', ''],
  })

  return await splitter.splitDocuments(docs)
}

/**
 * ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªå†…ã®å…¨ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿ã€ãƒãƒ£ãƒ³ã‚¯ã«åˆ†å‰²ã™ã‚‹
 * @param dirPath ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãƒ‘ã‚¹
 * @param extensions å¯¾è±¡æ‹¡å¼µå­ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: ['.txt', '.md']ï¼‰
 * @param chunkSize ãƒãƒ£ãƒ³ã‚¯ã‚µã‚¤ã‚º
 * @param chunkOverlap ãƒãƒ£ãƒ³ã‚¯ã‚ªãƒ¼ãƒãƒ¼ãƒ©ãƒƒãƒ—
 * @returns åˆ†å‰²ã•ã‚ŒãŸãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆé…åˆ—
 */
export async function loadDocumentsFromDirectory(
  dirPath: string,
  extensions: string[] = ['.txt', '.md'],
  chunkSize: number = 1000,
  chunkOverlap: number = 200
): Promise<Document[]> {
  const allDocs: Document[] = []

  if (!fs.existsSync(dirPath)) {
    throw new Error(`Directory not found: ${dirPath}`)
  }

  const files = fs.readdirSync(dirPath)

  for (const file of files) {
    const ext = path.extname(file).toLowerCase()
    if (extensions.includes(ext)) {
      const filePath = path.join(dirPath, file)
      console.log(`Loading: ${filePath}`)
      const docs = await loadAndSplitDocument(filePath, chunkSize, chunkOverlap)
      allDocs.push(...docs)
    }
  }

  return allDocs
}

/**
 * ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’ChromaDBã«ç™»éŒ²ã™ã‚‹
 * @param dirPath ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆãŒæ ¼ç´ã•ã‚Œã¦ã„ã‚‹ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
 * @param ollamaUrl Ollama APIã®URL
 * @param embeddingModel Embeddingãƒ¢ãƒ‡ãƒ«å
 * @param chromaUrl ChromaDB URL
 * @param collectionName ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³å
 */
export async function loadDocumentsToChroma(
  dirPath: string,
  ollamaUrl: string = 'http://localhost:11434',
  embeddingModel: string = 'nomic-embed-text',
  chromaUrl: string = DEFAULT_CHROMA_CONFIG.url,
  collectionName: string = DEFAULT_CHROMA_CONFIG.collectionName
): Promise<void> {
  console.log('ğŸ“š Loading documents from:', dirPath)

  const documents = await loadDocumentsFromDirectory(dirPath)
  console.log(`ğŸ“„ Loaded ${documents.length} chunks`)

  if (documents.length === 0) {
    throw new Error('No documents found to load')
  }

  console.log('ğŸ”„ Creating embeddings with model:', embeddingModel)
  const embeddings = createOllamaEmbeddings(ollamaUrl, embeddingModel)

  console.log('ğŸ’¾ Storing in ChromaDB collection:', collectionName)
  await createChromaCollection(documents, embeddings, {
    collectionName,
    url: chromaUrl,
  })

  console.log('âœ… Documents loaded successfully!')
}

# LeRobotとロボット制御について

## 技術的な説明

Action Chunking Transformer（ACT）で、視覚入力から動作系列を生成している。
学習データは人間のデモンストレーションから取得。

## 学習データの詳細

- 自宅で50回のデモンストレーションを収集
- うち3回はわざと指を出さずに「動かさない」ケースをテスト
- 残りの約半分は1回の指タッチ
- もう半分は2回連続で指タッチして、連続動作ができるか試している

## カメラ構成

- 横カメラと斜め後ろカメラの2台構成
- 専用カメラではなく普通のWebカメラを使用
- 汎用的なデバイスで実用的なロボットアーム操作ができるか検証中

## トレーニング環境

- Google Cloud の Vertex AI でトレーニングを実行
- 家以外の場所で試すのは今回が初めて
- うまくいかないこともあるかもしれないので、多めに見てほしい！
